PrÃ¡ctica 1 â€“ PerceptrÃ³n Multicapa (MLP) para PredicciÃ³n de SatisfacciÃ³n Laboral

Este proyecto implementa un PerceptrÃ³n Multicapa (MLP) para predecir el nivel de satisfacciÃ³n de empleados utilizando un dataset de desempeÃ±o y productividad.
La prÃ¡ctica estÃ¡ dividida en varias actividades que abarcan:

AnÃ¡lisis exploratorio

Procesamiento de datos

ConstrucciÃ³n de modelos MLP

Entrenamiento y evaluaciÃ³n

VisualizaciÃ³n de resultados

ğŸ“Š DescripciÃ³n del Proyecto

El Ã¡rea de Recursos Humanos recolectÃ³ mÃºltiples mÃ©tricas de desempeÃ±o, productividad y comportamiento de los empleados.
El objetivo es estimar el Employee Satisfaction Score, que originalmente es una variable numÃ©rica, pero se transforma a 5 categorÃ­as (0 a 4) para tratarlo como un problema de clasificaciÃ³n multiclase.

Este proyecto entrena tres arquitecturas diferentes de redes neuronales tipo MLP y evalÃºa cuÃ¡l generaliza mejor sobre los datos.

 Contenido de la PrÃ¡ctica
ğŸ”¹ Actividad 1 â€“ PreparaciÃ³n de Datos

Se realizan las siguientes tareas:

Carga del archivo CSV

SelecciÃ³n de columnas numÃ©ricas

VisualizaciÃ³n de distribuciones

EstandarizaciÃ³n con StandardScaler

DivisiÃ³n en entrenamiento/prueba (67% / 33%)

ConversiÃ³n del target a categorÃ­as 0â€“4

One-hot encoding para el entrenamiento con softmax

ğŸ”¹ Actividad 2 â€“ ImplementaciÃ³n de 3 Arquitecturas MLP

Se construyen tres modelos distintos usando TensorFlow/Keras:

ğŸ”µ MLP Simple

1 capa densa oculta

Pocas neuronas

Baseline rÃ¡pido
Ideal para comparar contra modelos mÃ¡s complejos.

ğŸŸ¢ MLP Deep

Arquitectura profunda

Varias capas densas

Aprende patrones mÃ¡s complejos
Adecuado para datasets con relaciones no lineales.

ğŸ”´ MLP Regularized

Uso de BatchNormalization

Uso de Dropout

Reduce el riesgo de sobreajuste
Especialmente Ãºtil en datasets pequeÃ±os o ruidosos.

Cada modelo tiene su propio nombre dentro de Keras.

ğŸ”¹ Actividad 3 â€“ CompilaciÃ³n y Entrenamiento

Cada modelo se compila con:
optimizer='adam'
loss='categorical_crossentropy'
metrics=['accuracy']

Y se entrena con diferentes cantidades de epochs segÃºn su complejidad:

MLP_simple â†’ 50 epochs

MLP_deep â†’ 70 epochs

MLP_regularized â†’ 100 epochs

AdemÃ¡s, se entrena con los datos estandarizados y etiquetas one-hot.

ğŸ”¹ Actividad 4 â€“ EvaluaciÃ³n y VisualizaciÃ³n

Se generan:

âœ” GrÃ¡ficas de aprendizaje:

Accuracy vs Epoch

Loss vs Epoch

ComparaciÃ³n entre los tres modelos

âœ” Matriz de confusiÃ³n

Para identificar quÃ© clases se confunden entre sÃ­.

âœ” Classification report

Incluye:

Precision

Recall

F1-score

Esto permite determinar quÃ© modelo generaliza mejor y cuÃ¡l tiene mejor rendimiento global.
